<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>【机器学习】GAN探究2——动漫头像生成 | One day, New day.</title><meta name="keywords" content="python,pytorch,GAN,ML"><meta name="author" content="秦政,qinzheng7575@gmail.com"><meta name="copyright" content="秦政"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="本人主页 三个阶段：    首先根据这个看一看，试着做一次     然后是书上的生成动漫头像    最后是使用数据集的这个例子   emoji集合~ [toc] 前言在基本的GAN熟知了之后，我们先聊一聊上次的第一部分做了什么：首先，我们有一堆按照某个规律分布的数据，但是我们完全不知道它的特点，比如在这里我们就在这两条线之间生成了样例数据，显然，这个样例数据似乎也长着一个二次曲线的样子。   经过">
<meta property="og:type" content="article">
<meta property="og:title" content="【机器学习】GAN探究2——动漫头像生成">
<meta property="og:url" content="http://example.com/2021/08/02/ML_GAN_2/index.html">
<meta property="og:site_name" content="One day, New day.">
<meta property="og:description" content="本人主页 三个阶段：    首先根据这个看一看，试着做一次     然后是书上的生成动漫头像    最后是使用数据集的这个例子   emoji集合~ [toc] 前言在基本的GAN熟知了之后，我们先聊一聊上次的第一部分做了什么：首先，我们有一堆按照某个规律分布的数据，但是我们完全不知道它的特点，比如在这里我们就在这两条线之间生成了样例数据，显然，这个样例数据似乎也长着一个二次曲线的样子。   经过">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdnimg.cn/98d5af9bf97949ce9be9cd665c0394c1.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center">
<meta property="article:published_time" content="2021-08-02T06:47:37.050Z">
<meta property="article:modified_time" content="2021-08-05T01:45:07.478Z">
<meta property="article:author" content="秦政">
<meta property="article:tag" content="啦啦啦">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/98d5af9bf97949ce9be9cd665c0394c1.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="http://example.com/2021/08/02/ML_GAN_2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-08-05 09:45:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://qinzheng7575-1.oss-cn-beijing.aliyuncs.com/touxiang.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">25</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fas fa-images"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://img-blog.csdnimg.cn/98d5af9bf97949ce9be9cd665c0394c1.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">One day, New day.</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/photos/"><i class="fa-fw fas fa-images"></i><span> 图库</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【机器学习】GAN探究2——动漫头像生成</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-08-02T06:47:37.050Z" title="Created 2021-08-02 14:47:37">2021-08-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-08-05T01:45:07.478Z" title="Updated 2021-08-05 09:45:07">2021-08-05</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><strong><a target="_blank" rel="noopener" href="https://qinzheng7575.github.io/">本人主页</a></strong></p>
<p>三个阶段：</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox">  首先根据<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/117529144">这个看一看</a>，试着做一次 </p>
</li>
<li><p><input checked="" disabled="" type="checkbox">  然后是书上的生成动漫头像</p>
</li>
<li><p><input disabled="" type="checkbox">  最后是使用数据集的<a target="_blank" rel="noopener" href="https://pytorch.apachecn.org/docs/1.4/13.html">这个例子</a></p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wangjs-jacky/p/12011208.html">emoji集合~</a></p>
<p>[toc]</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在基本的GAN熟知了之后，我们先聊一聊上次的第一部分做了什么：首先，我们有一堆按照某个规律分布的数据，但是我们完全不知道它的特点，比如在这里我们就在这两条线之间生成了样例数据，显然，这个样例数据似乎也长着一个二次曲线的样子。</p>
<img src="https://img-blog.csdnimg.cn/c898a18e2be744928b5baea149cbe23f.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />

<p>经过GAN的对抗之后，生成器生成的数据已经很接近二次曲线形状了。并且当我把样例数据的分布改变——比如改成在$y=x+1$附近的时候，也能够生成差不多对应的直线。</p>
<p>那么，如果我们的输入，不再是简单的线性分布，而是一张图片呢？看起来其实也就是把真实样本数据的输入维数64×15变成了64×15×3（rgb），但此时就应用到另一个针对图片的工具，CNN，所以就诞生了DCGAN。</p>
<blockquote>
<p>数据集来源：scraped from <a target="_blank" rel="noopener" href="https://www.kaggle.com/soumikrakshit/www.getchu.com">www.getchu.com</a>, which are then cropped using the anime face detection algorithm in <a target="_blank" rel="noopener" href="https://github.com/nagadomi/lbpcascade_animeface">https://github.com/nagadomi/lbpcascade_animeface</a>. </p>
</blockquote>
<h2 id="代码中的小知识点"><a href="#代码中的小知识点" class="headerlink" title="代码中的小知识点"></a>代码中的小知识点</h2><h3 id="feature-map是什么"><a href="#feature-map是什么" class="headerlink" title="feature map是什么"></a>feature map是什么</h3><p>在代码中，有<code>ngf</code>和<code>nz</code>两个变量，一开始不知道其作用的时候很是头疼。</p>
<blockquote>
<p>在每个卷积层，数据都是以三维形式存在的。<br>你可以把它看成许多个二维图片叠在一起，其中每一个称为一个feature map。<br>在输入层，如果是灰度图片，那就只有一个feature map；如果是彩色图片，一般就是3个feature map（红绿蓝）。<br>层与层之间会有若干个卷积核（kernel），上一层和每个feature map跟每个卷积核做卷积，都会产生下一层的一个feature map。</p>
<p>不同的Filter (不同的 weight, bias) ，卷积以后得到不同的 feature map，提取不同的特征（得到对应 specialized  neuro）</p>
<p>举例：同一层：</p>
<p> Fliter1 的w1,b1 运算后提取的是 形状边缘的特征： feature map1</p>
<p> Fliter2 的w2,b2 运算后提取的是 颜色深浅的特征： feature map2</p>
<p>下一层：</p>
<p> Fliter3 的w3,b3 运算后提取的是 直线形状的特征： feature map3</p>
<p> Fliter4 的w4,b4 运算后提取的是 弧线形状的特征： feature map4</p>
<p> Fliter5 的w5,b5 运算后提取的是 红色深浅的特征： feature map5</p>
<p> Fliter6 的w6,b6 运算后提取的是 绿色深浅的特征： feature map6</p>
<p>作者：花花儿<br>链接：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/31318081/answer/182488143">https://www.zhihu.com/question/31318081/answer/182488143</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
</blockquote>
<p>在卷积进行特征提取的时候，使用多个卷积核进行卷积再组合在一起，也会形成feature map</p>
<img src="https://img-blog.csdnimg.cn/712285e8d79e41e0becce2ccef7a1669.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" />

<h3 id="一些函数"><a href="#一些函数" class="headerlink" title="一些函数"></a>一些函数</h3><p>1、nn.Conv2d和nn.ConvTranspose2d参数说明及区别</p>
<blockquote>
<p>nn.Conv2d(in_channels，out_channels，kernel_size，stride=1，padding=0，dilation=1，groups=1，bias=True)</p>
<p>in_channels：输入维度<br>out_channels：输出维度<br>kernel_size：卷积核大小<br>stride：步长大小<br>padding：补0<br>dilation：kernel间距<br>groups(int, optional) ： 从输入通道到输出通道的阻塞连接数</p>
<p>nn.Conv2d的功能是：对由多个输入平面组成的输入信号进行二维卷积。</p>
<p>经过卷积后的图像尺寸计算公式：N = (W − F + 2P )/S+1</p>
<p>w为原始图像大小、F为卷积核尺寸、P为padding大小、S是步长</p>
</blockquote>
<p>2、pytorch中反卷积的函数为：</p>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;<span class="class"><span class="keyword">class</span> <span class="title">torch</span>.<span class="title">nn</span>.<span class="title">ConvTranspose2d</span>(<span class="params">in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                                                    output_padding=<span class="number">0</span>, groups=<span class="number">1</span>, bias=<span class="literal">True</span>, dilation=<span class="number">1</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>参数的含义如下：</p>
<ul>
<li>in_channels(int) – 输入信号的通道数</li>
<li>out_channels(int) – 卷积产生的通道数</li>
<li>kerner_size(int or tuple) - 卷积核的大小</li>
<li>stride(int or tuple,optional) - 卷积步长，即要将输入扩大的倍数。</li>
<li>padding(int or tuple, optional) - 输入的每一条边补充0的层数，高宽都增加2*padding</li>
<li>output_padding(int or tuple, optional) - 输出边补充0的层数，高宽都增加padding</li>
<li>groups(int, optional) – 从输入通道到输出通道的阻塞连接数</li>
<li>bias(bool, optional) - 如果bias=True，添加偏置</li>
<li>dilation(int or tuple, optional) – 卷积核元素之间的间距</li>
</ul>
<p>对于每一条边输入输出的尺寸的公式如下：</p>
<p>$output=(input-1)<em>stride+output_padding-2</em>padding+kernel_size$</p>
</blockquote>
<p><strong>重要：</strong><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/163017446">关于卷积中几个参数的数学定义</a></p>
<p>很简单的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.ConvTranspose2d(opt.nz, ngf* <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>其中输入的<code>opt.nz</code>是输入为nz维度（输入通道数为nz）的噪声：nz*1*1，那么这条语句实际上就是把一个<code>nz</code>个通道的1×1的像素，扩展到了有<code>nz×8</code>个通道，4×4的feature map</p>
<p>3、nn.BatchNorm2d()函数</p>
<blockquote>
<p>机器学习中，进行模型训练之前，需对数据做归一化处理，使其分布一致。在深度神经网络训练过程中，通常一次训练是一个batch，而非全体数据。每个batch具有不同的分布产生了internal covarivate shift问题——在训练过程中，数据分布会发生变化，对下一层网络的学习带来困难。Batch Normalization将数据拉回到均值为0，方差为1的正态分布上(归一化)，一方面使得数据分布一致，另一方面避免梯度消失、梯度爆炸。<br>————————————————<br>版权声明：本文为CSDN博主「宁静致远*」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40522801/article/details/106185263">https://blog.csdn.net/weixin_40522801/article/details/106185263</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">torch</span>.<span class="title">nn</span>.<span class="title">BatchNorm2d</span>(<span class="params">num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>其中<code>num_features</code>是指输入的channel数。</p>
<p>4、解决一个小报错</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/chen645096127/article/details/94019443">参考</a></p>
<p>在使用<code>errorg_meter.add(error_g.data[0])</code>时会报错，经检查，是因为pytorch版本更新的原因，改成<code>errorg_meter.add(error_g.item())</code>就好了。:kissing_heart:</p>
<p>5、LeakyRelu()函数</p>
<p>LeakrReLU和ReLU的区别就在于小于0的部分，仍有微小的梯度（下图右者）</p>
<img src="https://img-blog.csdnimg.cn/40b05d59aa804111acafb2414fa595e3.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="img" style="zoom:67%;" />

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/172254089">参考，讲的很详细</a></p>
<h3 id="Fire是什么"><a href="#Fire是什么" class="headerlink" title="Fire是什么"></a>Fire是什么</h3><p><a target="_blank" rel="noopener" href="https://github.com/google/python-fire/blob/master/docs/guide.md">Google的python fire文档</a></p>
<p>Fire，是为了更好在命令行输入参数来控制程序的，具体内容参考另一篇博客：</p>
<h3 id="Adam优化器是什么"><a href="#Adam优化器是什么" class="headerlink" title="Adam优化器是什么"></a>Adam优化器是什么</h3><p><strong>简单的来说，就是“动量+自适应学习率”</strong>——以下参考李宏毅的课</p>
<h4 id="动量momentum"><a href="#动量momentum" class="headerlink" title="动量momentum"></a>动量momentum</h4><p>如下图所示，我们的梯度下降过程，就好像是一个小球滚落山谷最后达到最低点的过程，但是呢，就很容易被暂时的花花风景迷了眼（掉入局部最优中）。</p>
<p>想一想现实中是怎么做的，没错，小球的运动不仅收到当前梯度的影响，还存在着惯性，而动量momentum的思想就是赋予小球“冲过”局部最优的能力。</p>
<img src="https://img-blog.csdnimg.cn/89e4203d41ff4085a28fa5a34866be10.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="img" style="zoom:67%;" />

<img src="https://img-blog.csdnimg.cn/a07c70dd28af4042b8eadc6dc6c00c9f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="img" style="zoom:67%;" />

<p>按照上图所示，在某一点的最终更新梯度是梯度矢量和动量矢量的和，动量矢量描述为当前的“速度”，而其中的动量：<br>$$<br>\begin{gather}<br>m^0=0\<br>m^1=-\eta g^0\<br>m^2=-\lambda\eta g^0-\eta g^1<br>\end{gather}<br>$$<br>从形式上看，动量的大小其实也是过去每一步的梯度的加权和，所以最终的效果就是梯度下降的方向不仅由$\partial L/\partial W$决定啦</p>
<h4 id="自适应学习率"><a href="#自适应学习率" class="headerlink" title="自适应学习率"></a>自适应学习率</h4><p>自适应学习率这一块，也有个很简单的原理：<strong>我们希望在平坦的路上步子迈大点，在陡峭的山坡上步子小一点</strong></p>
<img src="https://img-blog.csdnimg.cn/9d89a238888449a196344d0b670c9085.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="img" style="zoom:67%;" />

<p>可以看到，有了$\sigma_i^t$的存在可以进行调整，第一步的时候，分子分母抵消，按照$\eta$进行下降，然后在第二步，可以看到，是对前面的梯度的模进行了一个平方平均。因此，在整体梯度比较小的时候，分子就小了，那么学习率就上去了，步长增大；反之步长减小。下图很形象;</p>
<img src="https://img-blog.csdnimg.cn/62cadbad93eb4e4bbe42cb02e21b2f28.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="img" style="zoom:67%;" />

<h2 id="代码详解"><a href="#代码详解" class="headerlink" title="代码详解"></a>代码详解</h2><p>遇到两个大问题：</p>
<ul>
<li><p><input checked="" disabled="" type="checkbox">  import numpy出错——应该是你的问题</p>
</li>
<li><p><input checked="" disabled="" type="checkbox">  visdom出错</p>
</li>
</ul>
<h3 id="读取图片之torchvision"><a href="#读取图片之torchvision" class="headerlink" title="读取图片之torchvision"></a>读取图片之torchvision</h3><p><a target="_blank" rel="noopener" href="https://pytorch-cn.readthedocs.io/zh/latest/torchvision/torchvision-transform/">官方文档</a></p>
<p>1.transforms.Scale(size)：改变图片的大小：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">crop = transforms.Scale(<span class="number">12</span>)</span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;1.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="built_in">type</span>(img))</span><br><span class="line">print(img.size)</span><br><span class="line"></span><br><span class="line">croped_img = crop(img)</span><br><span class="line">print(<span class="built_in">type</span>(croped_img))</span><br><span class="line">print(croped_img.size)</span><br><span class="line"></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">PIL</span>.<span class="title">PngImagePlugin</span>.<span class="title">PngImageFile</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">(<span class="params"><span class="number">64</span>, <span class="number">64</span></span>)</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> &#x27;<span class="title">PIL</span>.<span class="title">Image</span>.<span class="title">Image</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">(<span class="params"><span class="number">12</span>, <span class="number">12</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>​        可见把64*64的图片变成了12*12的。</p>
<p>2.transforms.CenterCrop(size)：中心切割</p>
<p>​        将给定的<code>PIL.Image</code>进行中心切割，得到给定的<code>size</code>，<code>size</code>可以是<code>tuple（元组）</code>：<code>(target_height, target_width)</code>。<code>size</code>也可以是一个<code>Integer</code>，在这种情况下，切出来的图片的形状是正方形。</p>
<p>3.transforms.ToTensor()：转化成tensor</p>
<p>​        把一个取值范围是<code>[0,255]</code>的<code>PIL.Image</code>或者<code>shape</code>为<code>(H,W,C)</code>的<code>numpy.ndarray</code>，转换成形状为<code>[C,H,W]</code>，取值范围是<code>[0,1.0]</code>的<code>torch.FloadTensor</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">data = np.random.randint(<span class="number">0</span>, <span class="number">255</span>, size=<span class="number">75</span>)</span><br><span class="line">img = data.reshape(<span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(img.shape)</span><br><span class="line">img_tensor = transforms.ToTensor()(img)  <span class="comment"># 转换成tensor</span></span><br><span class="line">print(img_tensor)</span><br><span class="line"></span><br><span class="line">(<span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">tensor([[[ <span class="number">97</span>, <span class="number">218</span>,   <span class="number">4</span>, <span class="number">139</span>,  <span class="number">32</span>],</span><br><span class="line">         [ <span class="number">65</span>, <span class="number">231</span>, <span class="number">181</span>,  <span class="number">86</span>, <span class="number">197</span>],</span><br><span class="line">         [<span class="number">242</span>,  <span class="number">10</span>, <span class="number">185</span>,  <span class="number">27</span>, <span class="number">158</span>],</span><br><span class="line">         [ <span class="number">95</span>,   <span class="number">0</span>,  <span class="number">47</span>,  <span class="number">88</span>,  <span class="number">46</span>],</span><br><span class="line">         [<span class="number">172</span>, <span class="number">210</span>,  <span class="number">41</span>, <span class="number">220</span>,  <span class="number">25</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">176</span>, <span class="number">225</span>,  <span class="number">14</span>, <span class="number">189</span>, <span class="number">164</span>],</span><br><span class="line">         [ <span class="number">40</span>, <span class="number">107</span>, <span class="number">231</span>, <span class="number">110</span>, <span class="number">171</span>],</span><br><span class="line">         [<span class="number">247</span>, <span class="number">128</span>, <span class="number">161</span>, <span class="number">128</span>,  <span class="number">43</span>],</span><br><span class="line">         [ <span class="number">50</span>,  <span class="number">51</span>,  <span class="number">36</span>, <span class="number">103</span>,  <span class="number">81</span>],</span><br><span class="line">         [<span class="number">107</span>,  <span class="number">25</span>,  <span class="number">66</span>, <span class="number">171</span>, <span class="number">202</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">115</span>, <span class="number">194</span>, <span class="number">103</span>, <span class="number">128</span>, <span class="number">105</span>],</span><br><span class="line">         [ <span class="number">78</span>,  <span class="number">75</span>, <span class="number">181</span>,   <span class="number">2</span>,  <span class="number">87</span>],</span><br><span class="line">         [ <span class="number">57</span>,  <span class="number">35</span>,  <span class="number">96</span>,  <span class="number">35</span>, <span class="number">168</span>],</span><br><span class="line">         [<span class="number">191</span>, <span class="number">143</span>, <span class="number">235</span>,  <span class="number">86</span>, <span class="number">139</span>],</span><br><span class="line">         [ <span class="number">52</span>,  <span class="number">60</span>,  <span class="number">57</span>, <span class="number">103</span>, <span class="number">174</span>]]], dtype=torch.int32)</span><br></pre></td></tr></table></figure>
<p>4.transforms.Normalize(mean, std)：将<code>Tensor</code>正则化</p>
<p>​        给定均值：<code>(R,G,B)</code> 方差：<code>（R，G，B）</code>，将会把<code>Tensor</code>正则化。即<code>Normalized_image=(image-mean)/std</code>。</p>
<h3 id="代码太长了，不管了，直接上吧，写到啥是啥"><a href="#代码太长了，不管了，直接上吧，写到啥是啥" class="headerlink" title="代码太长了，不管了，直接上吧，写到啥是啥"></a>代码太长了，不管了，直接上吧，写到啥是啥</h3><h4 id="网络构建"><a href="#网络构建" class="headerlink" title="网络构建"></a>网络构建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NetG</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    生成器定义</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, opt</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NetG, self).__init__()</span><br><span class="line">        ngf = opt.ngf  <span class="comment"># 生成器feature map数，opt是参数对象</span></span><br><span class="line"></span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># 输入是一个nz维度的噪声，我们可以认为它是一个1*1*nz的feature map</span></span><br><span class="line">            nn.ConvTranspose2d(opt.nz, ngf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">8</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 上一步的输出形状：(ngf*8) x 4 x 4</span></span><br><span class="line"></span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">8</span>, ngf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">4</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 上一步的输出形状： (ngf*4) x 8 x 8</span></span><br><span class="line"></span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">4</span>, ngf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 上一步的输出形状： (ngf*2) x 16 x 16</span></span><br><span class="line"></span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">2</span>, ngf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 上一步的输出形状：(ngf) x 32 x 32</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias=False),</span></span><br><span class="line">            nn.ConvTranspose2d(ngf, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Tanh()  <span class="comment"># 输出范围 -1~1 故而采用Tanh，如果要0`1则用Sigmod</span></span><br><span class="line">            <span class="comment"># 输出形状：3 x 96 x 96</span></span><br><span class="line">            <span class="comment"># 这一层的kernel需要变，符合图片64*64的大小</span></span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.main(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>
<p>​        在这里，做出了一个重要变化：原来的最后一个层的kernel是（5，3，1），这样就能根据公式$H_{out}=(H_{in}-1)<em>stride-2</em>padding+kernel_size$使得图片从32×32变成96×96，但是我们用的图片数据是64×64，所以调整kernel为（4，2，1），最后发现修改正确！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NetD</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    判别器定义</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, opt</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NetD, self).__init__()</span><br><span class="line">        ndf = opt.ndf</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># 输入 3 x 96 x 96</span></span><br><span class="line">            <span class="comment"># nn.Conv2d(3, ndf, 5, 3, 1, bias=False),</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, ndf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line"></span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 输出 (ndf) x 32 x 32</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(ndf, ndf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 输出 (ndf*2) x 16 x 16</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">2</span>, ndf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 输出 (ndf*4) x 8 x 8</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">4</span>, ndf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">8</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 输出 (ndf*8) x 4 x 4</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">8</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()  <span class="comment"># 输出一个数(判断是真图片的概率)</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.main(<span class="built_in">input</span>).view(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>​        其实生成器和判别器的构造都比较简单的，生成器把一个<code>nz*1*1</code>的噪声，逐步上卷积到<code>3*64*64</code>，但是注意最后生成的矩阵每一个元素都是-1~1的，所以并不是直接的图像。</p>
<p>​        判别器则是不断卷积，并使用LeakyReLU代替的ReLU，最后是输出一个数，即判断是真图片的概率。</p>
<h4 id="配置所需参数"><a href="#配置所需参数" class="headerlink" title="配置所需参数"></a>配置所需参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Config</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    data_path = <span class="string">&#x27;data/&#x27;</span>  <span class="comment"># 数据集存放路径</span></span><br><span class="line">    num_workers = <span class="number">4</span>  <span class="comment"># 多进程加载数据所用的进程数</span></span><br><span class="line">    image_size = <span class="number">64</span>  <span class="comment"># 图片尺寸</span></span><br><span class="line">    batch_size = <span class="number">256</span></span><br><span class="line">    max_epoch = <span class="number">200</span></span><br><span class="line">    lr1 = <span class="number">2e-4</span>  <span class="comment"># 生成器的学习率</span></span><br><span class="line">    lr2 = <span class="number">2e-4</span>  <span class="comment"># 判别器的学习率</span></span><br><span class="line">    beta1 = <span class="number">0.5</span>  <span class="comment"># Adam优化器的beta1参数</span></span><br><span class="line">    gpu = <span class="literal">True</span>  <span class="comment"># 是否使用GPU</span></span><br><span class="line">    nz = <span class="number">100</span>  <span class="comment"># 噪声维度</span></span><br><span class="line">    ngf = <span class="number">64</span>  <span class="comment"># 生成器feature map数</span></span><br><span class="line">    ndf = <span class="number">64</span>  <span class="comment"># 判别器feature map数</span></span><br><span class="line"></span><br><span class="line">    save_path = <span class="string">&#x27;imgs/&#x27;</span>  <span class="comment"># 生成图片保存路径</span></span><br><span class="line"></span><br><span class="line">    vis = <span class="literal">True</span>  <span class="comment"># 是否使用visdom可视化</span></span><br><span class="line">    env = <span class="string">&#x27;GAN&#x27;</span>  <span class="comment"># visdom的env</span></span><br><span class="line">    plot_every = <span class="number">20</span>  <span class="comment"># 每间隔20 batch，visdom画图一次</span></span><br><span class="line"></span><br><span class="line">    debug_file = <span class="string">&#x27;/tmp/debuggan&#x27;</span>  <span class="comment"># 存在该文件则进入debug模式</span></span><br><span class="line">    d_every = <span class="number">1</span>  <span class="comment"># 每1个batch训练一次判别器</span></span><br><span class="line">    g_every = <span class="number">5</span>  <span class="comment"># 每5个batch训练一次生成器</span></span><br><span class="line">    decay_every = <span class="number">10</span>  <span class="comment"># 没10个epoch保存一次模型</span></span><br><span class="line">    netd_path = <span class="literal">None</span>  <span class="comment"># &#x27;checkpoints/netd_.pth&#x27; #预训练模型</span></span><br><span class="line">    netg_path = <span class="literal">None</span>  <span class="comment"># &#x27;checkpoints/netg_211.pth&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 只测试不训练</span></span><br><span class="line">    gen_img = <span class="string">&#x27;result.png&#x27;</span></span><br><span class="line">    <span class="comment"># 从512张生成的图片中保存最好的64张</span></span><br><span class="line">    gen_num = <span class="number">64</span></span><br><span class="line">    gen_search_num = <span class="number">512</span></span><br><span class="line">    gen_mean = <span class="number">0</span>  <span class="comment"># 噪声的均值</span></span><br><span class="line">    gen_std = <span class="number">1</span>  <span class="comment"># 噪声的方差</span></span><br><span class="line"></span><br><span class="line">opt = Config()<span class="comment">#实例化</span></span><br></pre></td></tr></table></figure>
<p>以上超参数设置就先这样吧，放在这后面再说。</p>
<h4 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">**kwargs</span>):</span></span><br><span class="line">    <span class="keyword">for</span> k_, v_ <span class="keyword">in</span> kwargs.items():</span><br><span class="line">        <span class="built_in">setattr</span>(opt, k_, v_)</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        将对象opt的属性k_改变为v_，这是一个很实用的写法！！！！！</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> opt.vis:  <span class="comment"># 使用visdom进行显示</span></span><br><span class="line">        <span class="keyword">from</span> visualize <span class="keyword">import</span> Visualizer</span><br><span class="line">        vis = Visualizer(opt.env)<span class="comment">#这个环境和咱们python的环境没关系，这里是&#x27;GAN&#x27;</span></span><br><span class="line"></span><br><span class="line">    transforms = tv.transforms.Compose([</span><br><span class="line">        tv.transforms.Scale(opt.image_size),</span><br><span class="line">        tv.transforms.CenterCrop(opt.image_size),</span><br><span class="line">        tv.transforms.ToTensor(),</span><br><span class="line">        tv.transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">    ])<span class="comment">#根据上面的介绍，将图片进行裁剪整理成Tensor</span></span><br><span class="line"></span><br><span class="line">    dataset = tv.datasets.ImageFolder(opt.data_path, transform=transforms)<span class="comment">#ImageFolder只是一个通用的数据加载器，咱们的图片已经按照了规定放置，就没问题了</span></span><br><span class="line">    dataloader = t.utils.data.DataLoader(dataset,</span><br><span class="line">                                         batch_size=opt.batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">True</span>,</span><br><span class="line">                                         num_workers=opt.num_workers,<span class="comment">#4个子进程</span></span><br><span class="line">                                         drop_last=<span class="literal">True</span></span><br><span class="line">                                         )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/data/">torch.utils.data的官方文档</a></p>
<p>​            我们用已经用<code>tv.datasets.ImageFolder</code>加载好了数据集，而<code>classtorch.utils.data.DataLoader</code>是一个数据加载器。组合数据集和采样器，并在数据集上提供单进程或多进程迭代器。</p>
<ul>
<li><strong>dataset</strong> (<em>Dataset</em>) – 加载数据的数据集。</li>
<li><strong>batch_size</strong> (<em>int</em>, optional) – 每个batch加载多少个样本(默认: 1)。</li>
<li><strong>shuffle</strong> (<em>bool</em>, optional) – 设置为<code>True</code>时会在每个epoch重新打乱数据(默认: False).</li>
<li><strong>num_workers</strong> (<em>int</em>, optional) – 用多少个子进程加载数据。0表示数据将在主进程中加载(默认: 0)</li>
<li><strong>drop_last</strong> (<em>bool</em>, optional) – 如果数据集大小不能被batch size整除，则设置为True后可删除最后一个不完整的batch。如果设为False并且数据集的大小不能被batch size整除，则最后一个batch将更小。(默认: False)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义网络</span></span><br><span class="line">netg, netd = NetG(opt), NetD(opt)<span class="comment">#实例化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map_location</span>(<span class="params">storage, loc</span>):</span> <span class="keyword">return</span> storage</span><br><span class="line"><span class="keyword">if</span> opt.netd_path:</span><br><span class="line">    netd.load_state_dict(t.load(opt.netd_path, map_location=map_location))</span><br><span class="line"><span class="keyword">if</span> opt.netg_path:</span><br><span class="line">    netg.load_state_dict(t.load(opt.netg_path, map_location=map_location))</span><br></pre></td></tr></table></figure>
<p>​        这是在加载预训练模型，我们在构造好了一个模型后，可能要加载一些训练好的模型参数，这时就可以。<a target="_blank" rel="noopener" href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#load_state_dictstate_dict">官方文档位置</a>，很值得看的一个<a target="_blank" rel="noopener" href="https://blog.csdn.net/t20134297/article/details/110533007?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control">博客</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义优化器和损失</span></span><br><span class="line">optimizer_g = t.optim.Adam(</span><br><span class="line">    netg.parameters(), opt.lr1, betas=(opt.beta1, <span class="number">0.999</span>))</span><br><span class="line">optimizer_d = t.optim.Adam(</span><br><span class="line">    netd.parameters(), opt.lr2, betas=(opt.beta1, <span class="number">0.999</span>))</span><br><span class="line">criterion = t.nn.BCELoss()  <span class="comment"># 损失函数：二值交叉熵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 真图片label为1，假图片label为0</span></span><br><span class="line"><span class="comment"># noises为生成网络的输入</span></span><br><span class="line">true_labels = Variable(t.ones(opt.batch_size))</span><br><span class="line">fake_labels = Variable(t.zeros(opt.batch_size))</span><br><span class="line">fix_noises = Variable(t.randn(opt.batch_size, opt.nz, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">noises = Variable(t.randn(opt.batch_size, opt.nz, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">errord_meter = AverageValueMeter()</span><br><span class="line">errorg_meter = AverageValueMeter()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>顾名思义，<strong>Variable</strong>就是 变量 的意思。实质上也就是可以变化的量，区别于int变量，它是一种可以变化的变量，这正好就符合了反向传播，参数更新的属性。</p>
<p>具体来说，在pytorch中的Variable就是一个存放会变化值的地理位置，里面的值会不停发生片花，就像一个装鸡蛋的篮子，鸡蛋数会不断发生变化。那谁是里面的鸡蛋呢，自然就是pytorch中的tensor了。（也就是说，<strong>pytorch都是有tensor计算的，而tensor里面的参数都是Variable的形式</strong>）。如果用Variable计算的话，那返回的也是一个同类型的Variable。</p>
<p><a target="_blank" rel="noopener" href="https://www.jb51.net/article/177996.htm">https://www.jb51.net/article/177996.htm</a></p>
</blockquote>
<blockquote>
<p><strong>AverageValueMeter(self)</strong></p>
<p>该<code>tnt.AverageValueMeter</code>返回的应该是统计量的均值。测量一组示例的平均损失很有用。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> opt.gpu:  <span class="comment"># 如果使用GPU，数据移到GPU上</span></span><br><span class="line">    netd.cuda()</span><br><span class="line">    netg.cuda()</span><br><span class="line">    criterion.cuda()</span><br><span class="line">    true_labels, fake_labels = true_labels.cuda(), fake_labels.cuda()</span><br><span class="line">    fix_noises, noises = fix_noises.cuda(), noises.cuda()</span><br><span class="line"></span><br><span class="line">    epochs = <span class="built_in">range</span>(opt.max_epoch)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">iter</span>(epochs):<span class="comment">#生成一个迭代器</span></span><br><span class="line">        <span class="keyword">for</span> ii, (img, _) <span class="keyword">in</span> tqdm.tqdm(<span class="built_in">enumerate</span>(dataloader)):</span><br><span class="line">            real_img = Variable(img)</span><br><span class="line">            <span class="keyword">if</span> opt.gpu:</span><br><span class="line">                real_img = real_img.cuda()</span><br><span class="line">                <span class="keyword">if</span> ii % opt.d_every == <span class="number">0</span>:<span class="comment"># 每1个batch训练一次判别器</span></span><br><span class="line">                    <span class="comment"># 训练判别器</span></span><br><span class="line">                    optimizer_d.zero_grad()</span><br><span class="line">                    <span class="comment"># 尽可能的把真图片判别为正确</span></span><br><span class="line">                    output = netd(real_img)  <span class="comment"># 前向传播</span></span><br><span class="line">                    error_d_real = criterion(output, true_labels)  <span class="comment"># 计算损失，二值交叉熵函数损失</span></span><br><span class="line">                    error_d_real.backward()  <span class="comment"># 反向传播</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 尽可能把假图片判别为错误</span></span><br><span class="line">                    noises.data.copy_(t.randn(opt.batch_size, opt.nz, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">                    fake_img = netg(noises).detach()  <span class="comment"># 根据噪声生成假图</span></span><br><span class="line">                    output = netd(fake_img)</span><br><span class="line">                    error_d_fake = criterion(output, fake_labels)</span><br><span class="line">                    error_d_fake.backward()</span><br><span class="line">                    optimizer_d.step()  <span class="comment"># 更新权重</span></span><br><span class="line">					<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">					！！！！！！！！！！！！！！！！！！！</span></span><br><span class="line"><span class="string">					注意看这里！先对网络进行了zero_grad()梯度清零，</span></span><br><span class="line"><span class="string">					然后netd(real_img)进行前向传播计算参数，</span></span><br><span class="line"><span class="string">					然后backward()反向传播计算梯度</span></span><br><span class="line"><span class="string">					最后两个反向传播都结束了，梯度都更新了，</span></span><br><span class="line"><span class="string">					optimizer_d.step()权重更新</span></span><br><span class="line"><span class="string">					！！！！！！！！！！！！！！！！！！！！</span></span><br><span class="line"><span class="string">					&#x27;&#x27;&#x27;</span></span><br><span class="line">                    error_d = error_d_fake + error_d_real</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># errord_meter.add(error_d.data[0])</span></span><br><span class="line">                    errord_meter.add(error_d.item())</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> ii % opt.g_every == <span class="number">0</span>:</span><br><span class="line">                        <span class="comment"># 训练生成器</span></span><br><span class="line">                        optimizer_g.zero_grad()</span><br><span class="line">                        noises.data.copy_(t.randn(opt.batch_size, opt.nz, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">                        fake_img = netg(noises)</span><br><span class="line">                        output = netd(fake_img)</span><br><span class="line">                        error_g = criterion(output, true_labels)</span><br><span class="line">                        error_g.backward()</span><br><span class="line">                        optimizer_g.step()</span><br><span class="line">                        <span class="comment"># errorg_meter.add(error_g.data[0])</span></span><br><span class="line">                        errorg_meter.add(error_g.item())</span><br></pre></td></tr></table></figure>
<p>可视化部分</p>
<p><a target="_blank" rel="noopener" href="https://github.com/fefit/visdom/wiki/%E4%B8%AD%E6%96%87API%E6%96%87%E6%A1%A3">visdom官方文档</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> opt.vis <span class="keyword">and</span> ii % opt.plot_every == opt.plot_every-<span class="number">1</span>:</span><br><span class="line">    <span class="comment"># 可视化</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(opt.debug_file):</span><br><span class="line">        ipdb.set_trace()</span><br><span class="line">        fix_fake_imgs = netg(fix_noises)</span><br><span class="line">        vis.images(fix_fake_imgs.data.cpu().numpy()</span><br><span class="line">                   [:<span class="number">64</span>]*<span class="number">0.5</span>+<span class="number">0.5</span>, win=<span class="string">&#x27;fixfake&#x27;</span>)</span><br><span class="line">        vis.images(real_img.data.cpu().numpy()</span><br><span class="line">                   [:<span class="number">64</span>]*<span class="number">0.5</span>+<span class="number">0.5</span>, win=<span class="string">&#x27;real&#x27;</span>)</span><br><span class="line">        vis.plot(<span class="string">&#x27;errord&#x27;</span>, errord_meter.value()[<span class="number">0</span>])</span><br><span class="line">        vis.plot(<span class="string">&#x27;errorg&#x27;</span>, errorg_meter.value()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch % opt.decay_every == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 保存模型、图片</span></span><br><span class="line">            tv.utils.save_image(fix_fake_imgs.data[:<span class="number">64</span>], <span class="string">&#x27;%s/%s.png&#x27;</span> % (</span><br><span class="line">                opt.save_path, epoch), normalize=<span class="literal">True</span>, <span class="built_in">range</span>=(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">            t.save(netd.state_dict(), <span class="string">&#x27;checkpoints/netd_%s.pth&#x27;</span> % epoch)</span><br><span class="line">            t.save(netg.state_dict(), <span class="string">&#x27;checkpoints/netg_%s.pth&#x27;</span> % epoch)</span><br><span class="line">            errord_meter.reset()</span><br><span class="line">            errorg_meter.reset()</span><br><span class="line">            optimizer_g = t.optim.Adam(</span><br><span class="line">                netg.parameters(), opt.lr1, betas=(opt.beta1, <span class="number">0.999</span>))</span><br><span class="line">            optimizer_d = t.optim.Adam(</span><br><span class="line">                netd.parameters(), opt.lr2, betas=(opt.beta1, <span class="number">0.999</span>))</span><br></pre></td></tr></table></figure>


<h4 id="生成结果"><a href="#生成结果" class="headerlink" title="生成结果"></a>生成结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate</span>(<span class="params">**kwargs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    随机生成动漫头像，并根据netd的分数选择较好的</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> k_, v_ <span class="keyword">in</span> kwargs.items():</span><br><span class="line">        <span class="built_in">setattr</span>(opt, k_, v_)<span class="comment">#从控制台的输入拿参数，可以进行默认参数的修改</span></span><br><span class="line"></span><br><span class="line">    netg, netd = NetG(opt).<span class="built_in">eval</span>(), NetD(opt).<span class="built_in">eval</span>()</span><br><span class="line">    noises = t.randn(opt.gen_search_num, opt.nz, <span class="number">1</span>,</span><br><span class="line">                     <span class="number">1</span>).normal_(opt.gen_mean, opt.gen_std)</span><br><span class="line">    noises = Variable(noises, volatile=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">map_location</span>(<span class="params">storage, loc</span>):</span> <span class="keyword">return</span> storage</span><br><span class="line">    netd.load_state_dict(t.load(opt.netd_path, map_location=map_location))</span><br><span class="line">    netg.load_state_dict(t.load(opt.netg_path, map_location=map_location))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> opt.gpu:</span><br><span class="line">        netd.cuda()</span><br><span class="line">        netg.cuda()</span><br><span class="line">        noises = noises.cuda()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成图片，并计算图片在判别器的分数</span></span><br><span class="line">    fake_img = netg(noises)</span><br><span class="line">    scores = netd(fake_img).data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 挑选最好的某几张</span></span><br><span class="line">    indexs = scores.topk(opt.gen_num)[<span class="number">1</span>]</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> indexs:</span><br><span class="line">        result.append(fake_img.data[ii])</span><br><span class="line">    <span class="comment"># 保存图片</span></span><br><span class="line">    tv.utils.save_image(t.stack(result), opt.gen_img,</span><br><span class="line">                        normalize=<span class="literal">True</span>, <span class="built_in">range</span>=(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> fire</span><br><span class="line">    fire.Fire()</span><br></pre></td></tr></table></figure>


<h2 id="最后结果"><a href="#最后结果" class="headerlink" title="最后结果"></a>最后结果</h2><p><img src="https://img-blog.csdnimg.cn/6d8d5d80b92944e78d76a78c90079e8b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom: 33%;" /><img src="https://img-blog.csdnimg.cn/9c82a75f232c40ada69d535d3e3b96ab.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:33%;" /><img src="https://img-blog.csdnimg.cn/d249b24084c24fda81dabf74add42b8c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:33%;" /></p>
<p><img src="https://img-blog.csdnimg.cn/15d6f0db803a4e89b49ee34a87cd07dd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:33%;" /><img src="https://img-blog.csdnimg.cn/7a0dd34d99ab495d8b32e14d2025446d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:33%;" /></p>
<p>如图，我训练了100个eopch，可以看到生成的图片逐渐有了动漫头像的感觉，相信如果训练的更多最后能够达到比较满意的结果~</p>
<p><em>2021.8.5</em></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:qinzheng7575@gmail.com">秦政</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2021/08/02/ML_GAN_2/">http://example.com/2021/08/02/ML_GAN_2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://img-blog.csdnimg.cn/98d5af9bf97949ce9be9cd665c0394c1.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/08/29/Python_fire/"><img class="prev-cover" src="https://img-blog.csdnimg.cn/577a9c30d2c44348a1607f3513239dce.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAUWluWmhlbmc3NTc1,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Python fire探究</div></div></a></div><div class="next-post pull-right"><a href="/2021/07/29/ML_GAN_1/"><img class="next-cover" src="https://img-blog.csdnimg.cn/374a996151e5482ca5a935c28dedea4e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">【机器学习】GAN探究</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://qinzheng7575-1.oss-cn-beijing.aliyuncs.com/touxiang.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">秦政</div><div class="author-info__description">Aloha！来访的人~</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">25</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Qinzheng7575" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:qinzheng7575@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9A%84%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-number">2.</span> <span class="toc-text">代码中的小知识点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#feature-map%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">2.1.</span> <span class="toc-text">feature map是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.</span> <span class="toc-text">一些函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fire%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">2.3.</span> <span class="toc-text">Fire是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Adam%E4%BC%98%E5%8C%96%E5%99%A8%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">2.4.</span> <span class="toc-text">Adam优化器是什么</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A8%E9%87%8Fmomentum"><span class="toc-number">2.4.1.</span> <span class="toc-text">动量momentum</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="toc-number">2.4.2.</span> <span class="toc-text">自适应学习率</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="toc-number">3.</span> <span class="toc-text">代码详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E5%9B%BE%E7%89%87%E4%B9%8Btorchvision"><span class="toc-number">3.1.</span> <span class="toc-text">读取图片之torchvision</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%A4%AA%E9%95%BF%E4%BA%86%EF%BC%8C%E4%B8%8D%E7%AE%A1%E4%BA%86%EF%BC%8C%E7%9B%B4%E6%8E%A5%E4%B8%8A%E5%90%A7%EF%BC%8C%E5%86%99%E5%88%B0%E5%95%A5%E6%98%AF%E5%95%A5"><span class="toc-number">3.2.</span> <span class="toc-text">代码太长了，不管了，直接上吧，写到啥是啥</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA"><span class="toc-number">3.2.1.</span> <span class="toc-text">网络构建</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%89%80%E9%9C%80%E5%8F%82%E6%95%B0"><span class="toc-number">3.2.2.</span> <span class="toc-text">配置所需参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">3.2.3.</span> <span class="toc-text">开始训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E7%BB%93%E6%9E%9C"><span class="toc-number">3.2.4.</span> <span class="toc-text">生成结果</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%90%8E%E7%BB%93%E6%9E%9C"><span class="toc-number">4.</span> <span class="toc-text">最后结果</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/08/29/Python_fire/" title="Python fire探究"><img src="https://img-blog.csdnimg.cn/577a9c30d2c44348a1607f3513239dce.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAUWluWmhlbmc3NTc1,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python fire探究"/></a><div class="content"><a class="title" href="/2021/08/29/Python_fire/" title="Python fire探究">Python fire探究</a><time datetime="2021-08-29T10:02:10.731Z" title="Created 2021-08-29 18:02:10">2021-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/02/ML_GAN_2/" title="【机器学习】GAN探究2——动漫头像生成"><img src="https://img-blog.csdnimg.cn/98d5af9bf97949ce9be9cd665c0394c1.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】GAN探究2——动漫头像生成"/></a><div class="content"><a class="title" href="/2021/08/02/ML_GAN_2/" title="【机器学习】GAN探究2——动漫头像生成">【机器学习】GAN探究2——动漫头像生成</a><time datetime="2021-08-02T06:47:37.050Z" title="Created 2021-08-02 14:47:37">2021-08-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/29/ML_GAN_1/" title="【机器学习】GAN探究"><img src="https://img-blog.csdnimg.cn/374a996151e5482ca5a935c28dedea4e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FpblpoZW5nNzU3NQ==,size_16,color_FFFFFF,t_70#pic_center" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】GAN探究"/></a><div class="content"><a class="title" href="/2021/07/29/ML_GAN_1/" title="【机器学习】GAN探究">【机器学习】GAN探究</a><time datetime="2021-07-29T11:28:14.352Z" title="Created 2021-07-29 19:28:14">2021-07-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/21/ML_AI_a_modern_approach/" title="【机器学习】读《人工智能-一种现代的方法》"><img src="https://img-blog.csdnimg.cn/img_convert/e49375ef568bbc4ec6baa8b67cdd61c8.png#pic_center" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】读《人工智能-一种现代的方法》"/></a><div class="content"><a class="title" href="/2021/07/21/ML_AI_a_modern_approach/" title="【机器学习】读《人工智能-一种现代的方法》">【机器学习】读《人工智能-一种现代的方法》</a><time datetime="2021-07-21T06:43:21.015Z" title="Created 2021-07-21 14:43:21">2021-07-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/20/ML_overview/" title="【机器学习】机器学习的分类——综述（更新中）"><img src="https://img-blog.csdnimg.cn/img_convert/bdcc653ac02825db94523904c680ed06.png#pic_center" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】机器学习的分类——综述（更新中）"/></a><div class="content"><a class="title" href="/2021/07/20/ML_overview/" title="【机器学习】机器学习的分类——综述（更新中）">【机器学习】机器学习的分类——综述（更新中）</a><time datetime="2021-07-20T08:58:11.635Z" title="Created 2021-07-20 16:58:11">2021-07-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021.1.30 - 2021 By 秦政</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'nFF9IEhO6zRX5WgaInbUlQE8-gzGzoHsz',
      appKey: 'XTFK0BpaRUndO938PLxwlbwM',
      placeholder: '少侠请留下个评论呗。',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script></div></body></html>